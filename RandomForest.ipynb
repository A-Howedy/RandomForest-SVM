{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42a9eb-cb87-4d78-abdc-e28887024093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "from math import log2, sqrt,ceil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a21da0-a070-43f4-a0e7-1d997f840549",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = np.random.PCG64()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009f1ce-0b7f-4014-afc7-f3a1af71e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index_numerical(above_split, below_split, attribute):\n",
    "    #UPDATING NOW INPUTS ARE DATAFRAMES\n",
    "    total_above = len(above_split)\n",
    "    total_below = len(below_split)\n",
    "    total = total_above + total_below\n",
    "    #for each class calculate the individual index\n",
    "    above_index = 0\n",
    "    below_index = 0\n",
    "    #probability point is above\n",
    "    #TODO OPTIMIZE\n",
    "    labels = ['0','1']\n",
    "    above_count = above_split['class'].value_counts()\n",
    "    below_count = below_split['class'].value_counts()\n",
    "    for i in range(0,len(labels)):\n",
    "        #check for empty frames\n",
    "        try:\n",
    "            p_above = 0 if above_split.empty else above_count[i] / total_above\n",
    "        except KeyError:\n",
    "            p_above = 0\n",
    "        try:\n",
    "            p_below = 0 if below_split.empty else below_count[i] / total_below\n",
    "        except KeyError:\n",
    "            p_below = 0\n",
    "        above_index += (p_above * p_above)\n",
    "        below_index += (p_below * p_below)\n",
    "    above_index = 1 - above_index\n",
    "    below_index = 1 - below_index\n",
    "    return (above_index * (total_above / total)) + (below_index * (total_below / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d063a0e-cc46-45be-b490-2113e1a684a6",
   "metadata": {},
   "source": [
    "gini_index_numerical takes in two n-d numpy arrays where n represents the number of potential classes. The above_split array represents all of the points located numerically above the split point and the below_split array represents the points with a lesser value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1e757-2755-4035-a4d8-71db4d34d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_calculation(splits, labels, total_in_set):\n",
    "    #calculate the total entropy by calculating the probabilities\n",
    "    entropy_before_split = 0\n",
    "    for label in range(0, len(labels)):\n",
    "        entropy_before_split += labels[label] / total_in_set\n",
    "    entropy = 0\n",
    "    for split in splits:\n",
    "        #for each split calculate the entropy for the given label set\n",
    "        split_entropy = 0\n",
    "        total_in_split = len(split)\n",
    "        label_count = split['class'].value_counts()\n",
    "        for label in range(0,len(labels)):\n",
    "            #calculating entropy\n",
    "            #need to get the values for each label within the split\n",
    "            #i.e. if split A has 15 values, 4 are class 0: 5 are class 1 and 6 are class 2\n",
    "            #class 0 would have 4/15 * log2(4/15)\n",
    "            try:\n",
    "                label_dist = 0 if split.empty else label_count[label] / total_in_split\n",
    "            except KeyError:\n",
    "                label_dist = 0\n",
    "            split_entropy = split_entropy if label_dist == 0 else (split_entropy + (label_dist * log2(label_dist)))\n",
    "            #split_entropy += (label_dist * log2(label_dist))\n",
    "        entropy += split_entropy\n",
    "    entropy = (-1)*(entropy)\n",
    "    return entropy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c378307-29ea-4012-a892-f537da2fe30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index_multiclass(splits, labels, total_in_set):\n",
    "    #calculate for each potential class\n",
    "    if not splits:\n",
    "        return 2\n",
    "    g_index = 0\n",
    "    for split in splits:\n",
    "        split_index = 0\n",
    "        label_count = split['class'].value_counts()\n",
    "        total_in_split = len(split)\n",
    "        #for label in labels:\n",
    "        for label in range(0,len(labels)):\n",
    "            try:\n",
    "                p_split = 0 if split.empty else (label_count[label] / total_in_split)\n",
    "            except (KeyError, IndexError):\n",
    "                p_split = 0\n",
    "            split_index += (p_split * p_split)\n",
    "        split_index = 1-split_index\n",
    "        g_index += (split_index * (total_in_split / total_in_set))\n",
    "    return g_index    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4f2b9-cc89-4e83-bd23-c743a02579b4",
   "metadata": {},
   "source": [
    "The gini_index_multiclass function takes in the splits, the attribute the set was split on, and the potential labels. The potential features should be defined as [0,1,...n-1] where n is the total number of features within the set. Possible feature values could depend on dataset (is pixel on or off, position of pixel, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc969034-a82d-4113-b8d0-fb86c3f71aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, splitting_point, split_values, split_feature):\n",
    "        self.split_values = split_values\n",
    "        self.split_feature = split_feature\n",
    "        #self.splitting_attribute = splitting_attribute\n",
    "        self.splitting_point = splitting_point\n",
    "        #TODO change to k for k classes?\n",
    "        if split_values == 0:\n",
    "            #self.children = np.zeros(2)\n",
    "            self.children = [0 for i in range(0,2)]\n",
    "        else:\n",
    "            #self.children = np.zeros(len(split_values))\n",
    "            self.children = [0 for i in range(0,len(split_values))]\n",
    "        self.children_split_length = np.zeros(len(self.children))\n",
    "    \n",
    "    def new_child_node(self, child_index, child, split_length):\n",
    "        #print(child_index, child)\n",
    "        self.children[child_index] = child\n",
    "        self.children_split_length[child_index] = split_length\n",
    "        \n",
    "    def __str__(self):\n",
    "        a = f\"splitting_point {self.splitting_point} , split_feature {self.split_feature}\\n\"\n",
    "        for idx, child in enumerate(self.children):\n",
    "            a += f\"child {idx}: {child}\"\n",
    "        return a\n",
    "    \n",
    "    def predict(self, point):\n",
    "        val = point[self.split_feature]\n",
    "        #child_index = self.children.index(val)\n",
    "        \n",
    "        #print(val, self.splitting_point, \"retrurning -> \")\n",
    "        if self.split_values == 0:\n",
    "            if val >= self.splitting_point:\n",
    "                #print(self.children[0])\n",
    "                return self.children[0]\n",
    "            else:\n",
    "                #print(self.children[1])\n",
    "                return self.children[1]\n",
    "        else:\n",
    "            #UPDATE THIS FUNCTION HOW TO FOLLOW PATH WHEN NON NUMERICAL?            \n",
    "            splitting_val = point[self.split_feature].split()\n",
    "            #GET INDEX OF THE VALUE IN SPLIT_VALUES WHIHC MATCHES INCOMING POINT?\n",
    "            #'?' represents an unknown value, how to deal with?\n",
    "            #perhaps follow split with most number of attributes?\n",
    "            if splitting_val[0] == \"?\":\n",
    "                #unknown follow feature attribute with most values?\n",
    "                #return index of max split value\n",
    "                child_index = np.argmax(self.children_split_length)\n",
    "            else:\n",
    "                child_index = self.split_values.index(splitting_val[0])\n",
    "            return self.children[child_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3403c09-2406-4546-94fb-f23d4314bf9e",
   "metadata": {},
   "source": [
    "The Node class represents each node within the tree. The splitting attribute and point determines the axis and value the node splits on. The above and below values represent the next node or label based on the splitting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4abdb2e-efec-4452-8616-891427844cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_continuous(value, attribute, examples):\n",
    "    #split where item in row > or < value\n",
    "    above_values = examples.loc[examples[attribute] >= value]\n",
    "    below_values = examples.loc[examples[attribute] < value]\n",
    "    return [above_values, below_values]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5aea2-534c-444a-9e14-3a16ac9bf4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_discrete(feature_name, feature_values, examples):\n",
    "    #split dataset based on all possible values\n",
    "    #TODO make this dynamically adjustable for when |features| > 2!\n",
    "    splits = []\n",
    "    for value in feature_values:\n",
    "        j_value = value.rjust(len(value)+1)\n",
    "        subset = examples.loc[examples[feature_name] == j_value]\n",
    "        splits.append(subset)\n",
    "    return splits                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d82d6b-a928-412f-bbc4-88547a31d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(examples, features, calculate_purity):\n",
    "    #given a dataframe -> examples find the best splitting value within based\n",
    "    #on the given purity calculation\n",
    "    #for row in examples\n",
    "        #for attribute in row\n",
    "            #value = row[attribute]\n",
    "            #split = split(value, examples)\n",
    "            #purity = calculate_purity(split)\n",
    "            #if purity better than best purity is best\n",
    "    #TODO OPTIMIZE THIS\n",
    "    best_purity = 2\n",
    "    best_node = None\n",
    "    best_splits = []\n",
    "    for index, row in examples.iterrows():\n",
    "        #loop through all features determining which are continous and which are discrete\n",
    "        #discrete -> pixel on / off or values such as couldy/rainy/windy\n",
    "        for feature_name, values in features.items():\n",
    "            \n",
    "            if(row[feature_name] == \"?\"):\n",
    "                print(\"UNKNOWN\")\n",
    "            if(values == 0):\n",
    "                #continous split based on current value in the row\n",
    "                try:\n",
    "                    splits = split_continuous(row[feature_name],feature_name,examples)\n",
    "                except (IndexError,KeyError):\n",
    "                    splits = []\n",
    "            else:\n",
    "                #split based on \n",
    "                splits = split_discrete(feature_name, values, examples)           \n",
    "            #split dataframe into 2 dataframes\n",
    "            #splits = split(row[val], val, examples)\n",
    "            #purity = calculate_purity(above_split, below_split, val)\n",
    "            purity = calculate_purity(splits, examples['class'].value_counts(), len(examples))\n",
    "            if purity < best_purity:\n",
    "                best_purity = purity\n",
    "                #create new node based on best attribute and value\n",
    "                best_node = Node(row[feature_name], values, feature_name)\n",
    "                best_splits = splits\n",
    "    return best_node, best_splits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855b368-2d5a-4293-bccc-408a035fc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_class(examples):\n",
    "    classes = examples['class'].value_counts()\n",
    "    return classes.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523ad33-9cf0-424a-8be7-1aa1770232a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_classes_in_samples(examples):\n",
    "        return len(examples['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f2b24-61fb-4665-b1eb-4aa809bc151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_tree(examples, features, parent_examples, depth, max_depth, calculate_purity):\n",
    "    #work with ending conditions, if no more examples left then return most common class in parent examples\n",
    "    if examples.empty or (number_of_classes_in_samples == 0):\n",
    "        return most_common_class(parent_examples)\n",
    "    elif (number_of_classes_in_samples(examples) == 1) or (depth >= max_depth):\n",
    "        return most_common_class(examples)\n",
    "    else:\n",
    "        #find the best split possible within the current split points\n",
    "        #splits[] = [above, below]\n",
    "        root_node, splits = find_best_split(examples, features, calculate_purity)\n",
    "        for i in range(0,len(splits)):\n",
    "            #above and below calculations\n",
    "            #split should consist of a subset of examples\n",
    "            new_node = learn_tree(splits[i],features, examples,depth-1,max_depth, calculate_purity)\n",
    "            root_node.new_child_node(i,new_node, len(splits[i]))\n",
    "        return root_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf18f39-2d96-4374-ace0-e10d6fe0ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_prediction(point, root_node):\n",
    "    prediction = root_node.predict(point)\n",
    "    while isinstance(prediction, Node):\n",
    "        prediction = prediction.predict(point)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3660aaef-e64b-4897-a0a2-24b261c89b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(data_frame, subset_length):\n",
    "    #randomly sample rows from the dataframe up to length n\n",
    "    #where n is the specified subset length\n",
    "    subset = data_frame.sample(n=subset_length, random_state=bg)    \n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c0b49-6f63-47e8-b0e0-0d5289790f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(data_frame, features, subset_length, max_depth, num_of_trees, purity_calculation):\n",
    "    trees = []\n",
    "    for i in range(0, num_of_trees):\n",
    "        #generate a random subsample\n",
    "        subset = get_subset(data_frame, subset_length)\n",
    "        #create the tree and append to list\n",
    "        tree = learn_tree(subset, features, None, 0, max_depth, purity_calculation)\n",
    "        trees.append(tree)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8d3effcf-4298-4a5f-bb1b-a396685ba2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data_with_trees(testing_data, trees, num_of_trees):\n",
    "    predicted_labels = []\n",
    "    for index, row in testing_data.iterrows():\n",
    "        predictions = np.zeros(num_of_trees)\n",
    "        for i in range(0,num_of_trees):\n",
    "            #casting to int because bincount does not like floating point\n",
    "            #print(f\"looking at tree {trees[i]}\")\n",
    "            #print(f\"NEW ELEMENT: {row}\")\n",
    "            predictions[i] = tree_prediction(row, trees[i])\n",
    "            #print(f\"result {predictions[i]}\")\n",
    "        #select maximum class, voting method\n",
    "        #print(\"done with predictions\")\n",
    "        most_voted_class = np.bincount(predictions.astype(np.int64)).argmax()\n",
    "        predicted_labels.append(most_voted_class)\n",
    "    return predicted_labels\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1fd90-b1ed-4ae0-9ff1-f3ecfd2704fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {'id': [1,2,3,4,5,6,7,8,9,10], '0': [1,12,4.3,6,14,2,9,14,5,4],'1':[4.5,7,1,3,4.8,15,17,7,1.9,10],'class':[0,1,0,0,1,0,1,1,0,0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05d94e-1440-4d7e-810e-4cf82332a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f31a4-8f16-4605-8883-f26126670c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221358ef-ffde-41c4-967f-88aa14b87e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = {'id': [1,2,3], '0': [1,19,11],'1':[4,12,11],'class':[0,1,1]}\n",
    "tdf = pd.DataFrame(data=testing)\n",
    "subset_length = sqrt(len(testing))\n",
    "predictions = []\n",
    "for num_of_trees in tree_nums:\n",
    "    trained_trees = random_forest(df,subset_length,max_depth,num_of_trees,entropy_calculation)\n",
    "    for root_node in trained_trees:\n",
    "        print(root_node)\n",
    "    predictions = predict_data_with_trees(tdf,trained_trees,num_of_trees)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c9bf5-e700-4deb-b80e-c70ddb0eaa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\"sepal length\":0,\"sepal width\":0,\"petal length\":0,\"pedal width\":0}\n",
    "f_names = [\"sepal length\",\"sepal width\",\"petal length\",\"petal width\",\"class\"]\n",
    "newdf = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",names=f_names)\n",
    "labelEnc = LabelEncoder()\n",
    "labelEnc.fit(newdf['class'])\n",
    "newdf['class'] = labelEnc.transform(newdf['class'])\n",
    "newdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2929f98-95e0-45e0-aca7-ce47e345b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"sepal length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76acf6e9-2272-487e-b399-fd6d70159ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = newdf['class'].value_counts()\n",
    "labels\n",
    "tree_nums = [10, 50, 150]\n",
    "max_depth = 10\n",
    "\n",
    "length_of_data = len(newdf)\n",
    "train_ratio = 0.7\n",
    "length_of_train = length_of_data * train_ratio\n",
    "train, test = train_test_split(newdf, test_size = 0.3, random_state = 43, shuffle=True)\n",
    "subset_length = ceil(sqrt(len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4819586f-71d1-4c3a-9315-7575d80f1b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587d1c2-cc76-4a3d-835c-c7cf588960b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_predictions = []\n",
    "for num_of_trees in tree_nums:\n",
    "    trained_trees = random_forest(train, features, subset_length, max_depth, num_of_trees, gini_index_multiclass)\n",
    "    predictions = predict_data_with_trees(test, trained_trees, num_of_trees)\n",
    "    i = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for ind, val in test['class'].items():\n",
    "        if predictions[i] == val:\n",
    "            correct+=1\n",
    "        i+=1\n",
    "        total+=1\n",
    "    print(f\"Correct classifications: {correct} | total {total}\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8049c853-e5d5-42d2-b7c2-84a7703e9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','class']\n",
    "adult = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names = f_names)\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9d8cf-22ef-421d-b21b-eaf58d8ab2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'age':0,\n",
    "            'workclass':[\"Private\", \"Self-emp-not-inc\", \"Self-emp-inc\", \"Federal-gov\", \"Local-gov\", \"State-gov\", \"Without-pay\", \"Never-worked\"],\n",
    "            'fnlwgt':0,\n",
    "            'education':['Bachelors', 'Some-college', '11th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc', '9th', '7th-8th', '12th', 'Masters', '1st-4th', '10th', 'Doctorate', '5th-6th', 'Preschool'],\n",
    "            'education-num':0,\n",
    "            'marital-status':['Married-civ-spouse', 'Divorced', 'Never-married', 'Separated', 'Widowed', 'Married-spouse-absent', 'Married-AF-spouse'],\n",
    "            'occupation':['Tech-support', 'Craft-repair', 'Other-service', 'Sales', 'Exec-managerial', 'Prof-specialty', 'Handlers-cleaners', 'Machine-op-inspct', 'Adm-clerical', 'Farming-fishing', 'Transport-moving', 'Priv-house-serv', 'Protective-serv', 'Armed-Forces'],\n",
    "            'relationship':['Wife', 'Own-child', 'Husband', 'Not-in-family', 'Other-relative', 'Unmarried'],\n",
    "            'race':['White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black'],\n",
    "            'sex':['Female', 'Male'],\n",
    "            'capital-gain':0,\n",
    "            'capital-loss':0,\n",
    "            'hours-per-week':0,\n",
    "            'native-country':['United-States', 'Cambodia', 'England', 'Puerto-Rico', 'Canada', 'Germany', 'Outlying-US(Guam-USVI-etc)', 'India', 'Japan', 'Greece', 'South', 'China', 'Cuba', 'Iran', 'Honduras', 'Philippines', 'Italy', 'Poland', 'Jamaica', 'Vietnam', 'Mexico', 'Portugal', \n",
    "                                'Ireland', 'France', 'Dominican-Republic', 'Laos', 'Ecuador', 'Taiwan', 'Haiti', 'Columbia', 'Hungary', 'Guatemala', 'Nicaragua', 'Scotland', 'Thailand', 'Yugoslavia', 'El-Salvador', 'Trinadad&Tobago', 'Peru', 'Hong', 'Holand-Netherlands']}\n",
    "labelEnc.fit(adult['class'])\n",
    "adult['class'] = labelEnc.transform(adult['class'])\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5989d5d-b71b-4cf7-9139-886d327f21ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "Correct classifications: 7804 | total 9769\n",
      "Correct classifications: 7940 | total 9769\n",
      "Correct classifications: 8035 | total 9769\n"
     ]
    }
   ],
   "source": [
    "adult_predictions = []\n",
    "max_depth = 10\n",
    "length_of_data = len(adult)\n",
    "train_ratio = 0.7\n",
    "train, test = train_test_split(adult, test_size = 0.3, random_state = 42, shuffle=True)\n",
    "subset_length = ceil(sqrt(len(train)))\n",
    "print(subset_length)\n",
    "tree_nums = [5,10,15]\n",
    "for num_of_trees in tree_nums:\n",
    "    trained_trees = random_forest(train, features, subset_length, max_depth, num_of_trees, gini_index_multiclass)\n",
    "    predictions = predict_data_with_trees(test, trained_trees, num_of_trees)\n",
    "    i = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for ind, val in test['class'].items():\n",
    "        if predictions[i] == val:\n",
    "            correct+=1\n",
    "        i+=1\n",
    "        total+=1\n",
    "    print(f\"Correct classifications: {correct} | total {total}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809da309-f3fb-472f-8d3f-9959514542cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trained_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb0b06-267d-45f5-a549-0990beb47ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict_data_with_trees(test, trained_trees, num_of_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697250c-fda2-4e38-a577-205724f1ba01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
